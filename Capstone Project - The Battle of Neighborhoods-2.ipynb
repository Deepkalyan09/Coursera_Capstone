{"cells": [{"metadata": {}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\nimport datetime as dt # Datetime\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium #import folium # map rendering library\n\nprint('Libraries imported.')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Read the data for examination (Source: http://landregistry.data.gov.uk/)\ndf_ppd = pd.read_csv(\"http://prod2.publicdata.landregistry.gov.uk.s3-website-eu-west-1.amazonaws.com/pp-2018.csv\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_ppd.head(5)\nOut[3]:\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf_ppd.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Assign meaningful column names\ndf_ppd.columns = ['TUID', 'Price', 'Date_Transfer', 'Postcode', 'Prop_Type', 'Old_New', 'Duration', 'PAON', \\\n                  'SAON', 'Street', 'Locality', 'Town_City', 'District', 'County', 'PPD_Cat_Type', 'Record_Status']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Format the date column\ndf_ppd['Date_Transfer'] = df_ppd['Date_Transfer'].apply(pd.to_datetime)\n\n# Delete all obsolete transactions which were done before 2016\ndf_ppd.drop(df_ppd[df_ppd.Date_Transfer.dt.year < 2016].index, inplace=True)\n\n# Sort by Date of Sale\ndf_ppd.sort_values(by=['Date_Transfer'],ascending=[False],inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf_ppd_london = df_ppd.query(\"Town_City == 'LONDON'\")\n\n# Make a list of street names in LONDON\nstreets = df_ppd_london['Street'].unique().tolist()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_grp_price = df_ppd_london.groupby(['Street'])['Price'].mean().reset_index()\n\n# Give meaningful names to the columns\ndf_grp_price.columns = ['Street', 'Avg_Price']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n#Input your Budget's Upper Limit and Lower Limit - Find the locations df_grp_price which fits your budget\ndf_affordable = df_grp_price.query(\"(Avg_Price >= 2200000) & (Avg_Price <= 2500000)\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Display the dataframe\ndf_affordable", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nimport datetime as DT\nimport hmac\nfrom geopy.geocoders import Nominatim\nfrom geopy.distance import vincenty\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for index, item in df_affordable.iterrows():\n    print(f\"index: {index}\")\n    print(f\"item: {item}\")\n    print(f\"item.Street only: {item.Street}\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "geolocator = Nominatim()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_affordable['city_coord'] = df_affordable['Street'].apply(geolocator.geocode).apply(lambda x: (x.latitude, x.longitude))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_affordable\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_affordable[['Latitude', 'Longitude']] = df_affordable['city_coord'].apply(pd.Series)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_affordable", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df = df_affordable.drop(columns=['city_coord'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ndf\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "address = 'London, UK'\n\ngeolocator = Nominatim()\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of London City are {}, {}.'.format(latitude, longitude))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create map of London using latitude and longitude values\nmap_london = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# add markers to map\nfor lat, lng, price, street in zip(df['Latitude'], df['Longitude'], df['Avg_Price'], df['Street']):\n    label = '{}, {}'.format(street, price)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_london)  \n    \nmap_london", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Define Foursquare Credentials and Version\n\nCLIENT_ID = 'KI3TR0QO4JOKMFELOMF3WSOOI3HFNBF5YLW354MYWBKDHEX3' # Foursquare ID\nCLIENT_SECRET = 'QF4ZBLJRBV4BQX52DVWUPEHJ14A2UJABPCZARZQZYTKIISUD' # Foursquare Secret\nVERSION = '20181206' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=100):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Street', \n                  'Street Latitude', \n                  'Street Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Run the above function on each location and create a new dataframe called location_venues and display it.\nlocation_venues = getNearbyVenues(names=df['Street'],\n                                   latitudes=df['Latitude'],\n                                   longitudes=df['Longitude']\n                                  )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "location_venues", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "location_venues.groupby('Street').count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# get the List of Unique Categories\nprint('There are {} uniques categories.'.format(len(location_venues['Venue Category'].unique())))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "location_venues.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\nvenues_onehot = pd.get_dummies(location_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add street column back to dataframe\nvenues_onehot['Street'] = location_venues['Street'] \n\n# move street column to the first column\nfixed_columns = [venues_onehot.columns[-1]] + list(venues_onehot.columns[:-1])\n\n#fixed_columns\nvenues_onehot = venues_onehot[fixed_columns]\n\nvenues_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped = venues_onehot.groupby('Street').mean().reset_index()\nlondon_grouped", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 5\n\nfor hood in london_grouped['Street']:\n    print(\"----\"+hood+\"----\")\n    temp = london_grouped[london_grouped['Street'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Street']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "venues_sorted = pd.DataFrame(columns=columns)\nvenues_sorted['Street'] = london_grouped['Street']\n\nfor ind in np.arange(london_grouped.shape[0]):\n    venues_sorted.iloc[ind, 1:] = return_most_common_venues(london_grouped.iloc[ind, :], num_top_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nvenues_sorted.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nvenues_sorted.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nlondon_grouped=df", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "kclusters = 5\n\nlondon_grouped_clustering = london_grouped.drop('Street', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(london_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:50]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering=df\nlondon_grouped_clustering.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.shape\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nlondon_grouped_clustering.dtypes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.dtypes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\nlondon_grouped_clustering['Cluster Labels'] = kmeans.labels_\n\n# merge london_grouped with london_data to add latitude/longitude for each neighborhood\nlondon_grouped_clustering = london_grouped_clustering.join(venues_sorted.set_index('Street'), on='Street')\n\nlondon_grouped_clustering.head(30) # check the last columns!", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create Map\n\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(london_grouped_clustering['Latitude'], london_grouped_clustering['Longitude'], london_grouped_clustering['Street'], london_grouped_clustering['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.loc[london_grouped_clustering['Cluster Labels'] == 0, london_grouped_clustering.columns[[1] + list(range(5, london_grouped_clustering.shape[1]))]].head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.loc[london_grouped_clustering['Cluster Labels'] == 1, london_grouped_clustering.columns[[1] + list(range(5, london_grouped_clustering.shape[1]))]].head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.loc[london_grouped_clustering['Cluster Labels'] == 2, london_grouped_clustering.columns[[1] + list(range(5, london_grouped_clustering.shape[1]))]].head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.loc[london_grouped_clustering['Cluster Labels'] == 3, london_grouped_clustering.columns[[1] + list(range(5, london_grouped_clustering.shape[1]))]].head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "london_grouped_clustering.loc[london_grouped_clustering['Cluster Labels'] == 4, london_grouped_clustering.columns[[1] + list(range(5, london_grouped_clustering.shape[1]))]].head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}